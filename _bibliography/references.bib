---
---
References
==========

@INPROCEEDINGS{volpetti2020,
title = {Temporal word embeddings for narrative understanding},
series = {ACM Press International Conference Proceedings Series},
publisher = {ACM},
booktitle = {Proceedings of the 12th International Conference on Machine Learning and Computing (ICMLC 2020)},
author = {Volpetti, Claudia and K, Vani and Antonucci, Alessandro},
pages = {},
year = {2020},
note = {ISBN: 978-1-4503-7642-6},
abstract={We propose temporal word embeddings as a suitable tool to study the evolution of characters and their sentiments across the plot of a narrative text. The dynamic evolution of instances within a narrative text is a challenging task, where complex behavioral evolutions and other characteristics specific to the narrative text need to be inferred and interpreted. While starting from an existing approach to the learning of these models, we propose an alternative initialization procedure which seems to be especially suited for the case of narrative text. As a validation benchmark, we use the Harry Potter series of books as a challenging case study for such character trait evolution. A benchmark data set based on temporal word analogies related to the characters in the plot of the series is considered. The results are promising, and the empirical validation seems to support the working ideas behind this proposal.}}

@inproceedings{antonucci2019a,
title = {Reliable discretisation of deterministic equations in Bayesian networks},
author = {Antonucci, A.},
booktitle = {Proceedings of the Thirty-Second International Florida Artificial Intelligence Research Society Conference, {FLAIRS} 2019, Sarasota, Florida, {USA} May 19-22 2019},
year = {2019},
pages = {453-457},
publisher = {AAAI Press},
abstract = {We focus on the problem of modeling deterministic equations over continuous variables in discrete Bayesian networks. This is typically achieved by a discretisation of both input and output variables and a degenerate quantification of the corre- sponding conditional probability tables. This approach, based on classical probabilities, cannot properly model the information loss induced by the discretisation. We show that a reli- able modeling of such epistemic uncertainty can be instead achieved by credal sets, i.e., convex sets of probability mass functions. This transforms the original Bayesian network in a credal network, possibly returning interval-valued inferences, that are robust with respect to the information loss induced by the discretisation. Algorithmic strategies for an optimal choice of the discretisation bins are also discussed.}}

@journal{antonucci2019b,
title = {Modeling Deterministic Equations in Discrete Bayesian Networks by Credal Networks},
author = {Alessandro Antonucci},
year={2018},
journal = {J. Phys.: Conf. Ser.},
volume = {1065},
issue = {212014}}

@inproceedings{antonucci2019c,
title = {Credal sentential decision diagrams},
author = {Antonucci, A. and Facchini, A. and Mattei, L.},
author =       {Antonucci, Alessandro and Facchini, Alessandro and Mattei, Lilith},
booktitle =    {Proceedings of the Eleventh International Symposium on Imprecise Probabilities: Theories and Applications},
pages =        {14--22},
year =         {2019},
editor =       {De Bock, Jasper and {de Campos}, Cassio P. and {de Cooman}, Gert and Quaeghebeur, Erik and Wheeler, Gregory},
volume =       {103},
series =       {Proceedings of Machine Learning Research},
address =      {Thagaste, Ghent, Belgium},
month =        {03--06 Jul},
publisher =    {PMLR},
pdf =          {http://proceedings.mlr.press/v103/antonucci19a/antonucci19a.pdf},
url =          {http://proceedings.mlr.press/v103/antonucci19a.html},
abstract =     {\emph{Probabilistic sentential decision diagrams} are logical circuits annotated by probability mass functions on the disjunctive gates. This allows for a compact representation of joint mass functions consistent with logical constraints. We propose a \emph{credal} generalisation of the probabilistic quantification of these models, that allows to replace the local probabilities with (credal) sets of mass functions specified by linear constraints. This induces a joint credal set, that sharply assigns probability zero to states inconsistent with the constraints. These models can support cautious estimates of the local parameters when only small amounts of training data are available. Algorithmic strategies to compute lower and upper bounds of marginal and conditional queries are provided. The task can be achieved in linear time with respect to the diagram size for marginal queries. The same can be done for conditional queries if the topology of the circuit is singly connected.}
}


@inproceedings{antonucci2019c,
title = {Exploring the space of probabilistic sentential decision diagrams},
author = {Mattei, L. and Soares, D.L. and Antonucci, A. and Mau√†, D.D. and Facchini, A.},
year = {2019},
abstract = {Probabilistic sentential decision diagrams (PS- DDs) are annotated circuits providing a possibly compact specification of joint probability mass functions consistent with a formula over a set of propositional variables. PSDD inference is tractable in the sense that marginal queries can be achieved in linear time with respect to the circuit size by traversal algorithms. Unlike other probabilistic graphical models such as Bayesian networks, the problem of learning the structure for PSDDs received relatively little attention. We discuss some preliminary ideas related to the development of pure likelihood-score-based search methods for the learning of PSDD structures fit- ting a formula and a data set of consistent obser- vations. A sampling algorithm for these models is also provided.},
booktitle = {Proceedings of the third Tractable Probabilistic Modeling Workshop, 36th International Conference on Machine Learning, Long Beach, California.},
url = {https://sites.google.com/view/icmltpm2019/home}}

@INPROCEEDINGS{antonucci2016d,
title = {Adaptive testing by {B}ayesian networks with application to language assessment},
editor = {Micarelli, Alessandro and Stamper, John and Panourgia, Kitty},
series = {Lecture Notes in Computer Science},
booktitle = {Intelligent Tutoring Systems: 13th International Conference, {ITS} 2016, Zagreb, Croatia, June 7-10, 2016. Proceedings},
author = {Mangili, F. and Bonesana, C. and Antonucci, A. and Zaffalon, M. and Rubegni, E. and Addimando, L.},
pages = {471--472},
year = {2016},
abstract={We present a general procedure for computerized adaptive testing based on probabilistic graphical models, and show on a real-world benchmark how this procedure can increase the internal consistency of the test and reduce the number of questions without affecting accuracy.},
url = {http://link.springer.com/content/pdf/bbm%3A978-3-319-39583-8%2F1.pdf}
}

@ARTICLE{antonucci2016c,
title = {The multilabel naive credal classifier},
journal = {International Journal of Approximate Reasoning},
author={Antonucci, Alessandro and Corani, Giorgio},
year = {2016},
volume={83},
pages={320--336},
year={2017},
publisher={Elsevier},
doi = {10.1016/j.ijar.2016.10.006},
abstract={A credal classifier for multilabel data is presented. This is obtained as an extension of Zaffalon's naive credal classifier to the case of non-exclusive class labels. The dependence relations among the labels are shaped with a tree topology. The classifier, based on a polynomial-time algorithm to compute whether or not a class label is optimal, returns a compact description of the set of optimal sequences of labels. Extensive experiments on real multilabel data show that the classifier gives more robust predictions than its Bayesian counterpart. In practice, when multiple sequences are returned in output, the Bayesian model is more likely to be inaccurate, while the sequences returned by the credal classifier are more likely to include the correct one.}}


@ARTICLE{antonucci2016b,
title = {Evaluating interval-valued influence diagrams},
journal = {International Journal of Approximate Reasoning},
author={Caba{\~n}as, Rafael and Antonucci, Alessandro and Cano, Andr{\'e}s and G{\'o}mez-Olmedo, Manuel},
journal={International Journal of Approximate Reasoning},
volume={80},
pages={393--411},
year={2017},
publisher={Elsevier},
abstract={Influence diagrams are probabilistic graphical models used to represent and solve sequential decision problems under uncertainty. Sharp numerical values are required to quantify probabilities and utilities. This might be an issue with real models, whose parameters are typically obtained from expert judgements or partially reliable data. We consider an interval-valued quantification of the parameters to gain realism in the modeling and evaluate the sensitivity of the inferences with respect to perturbations in the sharp values of the parameters. An extension of the classical influence diagrams formalism to support such interval-valued potentials is presented. The variable elimination and arc reversal inference algorithms are generalized to cope with these models. At the price of an outer approximation, the extension keeps the same complexity as with sharp values. Numerical experiments show improved performances with respect to previous methods. As a natural application, we propose these models for practical sensitivity analysis in traditional influence diagrams. The maximum perturbation level on single or multiple parameters preserving the optimal strategy can be computed. This allows the identification of the parameters deserving a more careful elicitation.}}

@INCOLLECTION{antonucci2016a,
title = {Technical gestures recognition by set-valued hidden {M}arkov models with prior knowledge},
editor = {Ferraro, M. B. and Giordani, P. and Vantaggi, B. and Gagolewski, M. and Gil, M. A. and Grzegorzewski, P. and Hryniewicz, O.},
publisher = {Springer},
series = {Advances in Intelligent Systems and Computing},
volume = {456},
booktitle = {Soft Methods for Data Science},
author = {Soullard, Y. and Antonucci, A. and Destercke, S.},
pages = {455--462},
year = {2017},
doi = {10.1007/978-3-319-42972-4_56},
abstract={Hidden Markov models are popular tools for gesture recognition. Once the generative processes of gestures have been identified, an observation sequence is usually classified as the gesture having the highest likelihood, thus ignoring possible prior information. In this paper, we consider two potential improvements of such methods: the inclusion of prior information, and the possibility of considering convex sets of probabilities (in the likelihoods and the prior) to infer imprecise, but more reliable, predictions when information is insufficient. We apply the proposed approach to technical gestures, typically characterized by severe class imbalance. By modelling such imbalances as a prior information, we achieve more accurate results, while the imprecise quantification is shown to produce more reliable estimates.}}

@INCOLLECTION{antonucci2015e,
title = {Imprecision in {M}achine {L}earning and {AI}},
publisher = {IEEE Computer Society},
volume = {16},
booktitle = {The {IEEE} Intelligent Informatics Bulletin},
author = {de Campos, C. and Antonucci, A.},
number = {1},
pages = {20--23},
year = {2015},
url = {http://www.comp.hkbu.edu.hk/~cib/2015/Dec/iib_vol16no1.pdf}}

@INPROCEEDINGS{antonucci2015d,
title = {Early classification of time series by hidden {M}arkov models with set-valued parameters  },
publisher = {Proceedings of the NIPS Time Series Workshop 2015},
author = {Antonucci, A. and Scanagatta, M. and Mau\`a, D. and de Campos, C.P.},
year = {2015},
url = {https://sites.google.com/site/nipsts2015/home}}


@ARTICLE{antonucci2015c,
   title = {Hidden {M}arkov models with set-valued parameters},
   journal = {Neurocomputing},
   author = {Mau\'a, D.D. and Antonucci, A. and de Campos, C.P.},
   doi = {doi:10.1016/j.neucom.2015.08.095},
abstract={Hidden Markov models (HMMs) are widely used probabilistic models of sequential data. As with other probabilistic models, they require the specification of local conditional probability distributions, whose assessment can be too difficult and error-prone, especially when data are scarce or costly to acquire. The imprecise HMM (iHMM) generalizes HMMs by allowing the quantification to be done by sets of, instead of single, probability dis- tributions. iHMMs have the ability to suspend judgment when there is not enough statistical evidence, and can serve as a sensitivity analysis tool for standard non-stationary HMMs. In this paper, we consider iHMMs under the strong independence interpretation, for which we develop efficient infer- ence algorithms to address standard HMM usage such as the computation of likelihoods and most probable explanations, as well as performing filter- ing and predictive inference. Experiments with real data show that iHMMs produce more reliable inferences without compromising the computational efficiency.},  
volume={180},
  pages={94--107},
  year={2016},
  publisher={Elsevier}
}



@INPROCEEDINGS{antonucci2015a,
title = {The multilabel naive credal classifier},
publisher = {SIPTA},
booktitle = {{ISIPTA} '15: Proceedings of the Ninth International Symposium on Imprecise Probability: Theories and Applications},
author = {Antonucci, A. and Corani, G.},
year = {2015},
abstract={We present a credal classifier for multilabel data. The model generalizes the naive credal classifier to the multilabel case. An imprecise-probabilistic quantifi- cation is achieved by means of the imprecise Dirichlet model in its global formulation. A polynomial-time algorithm to compute whether or not a label is opti- mal according to the maximality criterion is derived. Experimental results show the importance of robust predictions in multilabel problems.}}


@INPROCEEDINGS{antonucci2015b,
title = {Variable elimination for interval-valued influence diagrams},
booktitle = {Proceedings of the 13th European Conference on Symbolic and Quantitative Approaches to Reasoning {w}ith Uncertainty},
author = {Caba\~nas, R. and Antonucci, A. and Cano, A. and G\'omez-Olmedo, M.},
year = {2015},
abstract={Influence diagrams are probabilistic graphical models used to represent and solve decision problems under uncertainty. Sharp numerical values are required to quantify probabilities and utilities. Yet, real models are based on data streams provided by partially reliable sensors or experts. We propose an interval-valued quantification of these parameters to gain realism in the modelling and to analyse the sensitivity of the inferences with respect to perturbations of the sharp values. An extension of the classical influence diagrams formalism to support interval-valued potentials is provided. Moreover, a variable elimination algorithm especially designed for these models is developed and evalu- ated in terms of complexity and empirical performances.}}

@INPROCEEDINGS{antonucci2014g, 
author = {De Bock, J. and de Campos, C.P. and Antonucci, A.},
title = {Global sensitivity analysis for {MAP} inference in graphical models},
booktitle = {Advances in Neural Information Processing Systems 27 (NIPS 2014)},
abstract = {We study the sensitivity of a MAP configuration of a discrete probabilistic graph- ical model with respect to perturbations of its parameters. These perturbations are global, in the sense that simultaneous perturbations of all the parameters (or any chosen subset of them) are allowed. Our main contribution is an exact algorithm that can check whether the MAP configuration is robust with respect to given per- turbations. Its complexity is essentially the same as that of obtaining the MAP configuration itself, so it can be promptly used with minimal effort. We use our algorithm to identify the largest global perturbation that does not induce a change in the MAP configuration, and we successfully apply this robustness measure in two practical scenarios: the prediction of facial action units with posed images and the classification of multiple real public data sets. A strong correlation between the proposed robustness measure and accuracy is verified in both scenarios.},
year = {2014}}

@INPROCEEDINGS{antonucci2014f, 
author = {Corani, G. and Antonucci, A. and Mau\'a, D.D. and Gabaglio, S.},
title     = {Trading off speed and accuracy in multilabel classification},
booktitle = {PGM '14: Proceedings of the Seventh European Workshop on Probabilistic Graphical Models},
editor = {van der Gaag, L.C. and Feelders, A.},
series = {Lecture Notes in Artificial Intelligence},
publisher = {Springer},
year = {2014},
abstract = {In previous work, we devised an approach for multilabel classification based on an ensemble of Bayesian networks. It was characterized by an efficient structural learning and by high accuracy. Its shortcoming was the high computational complexity of the MAP inference, necessary to identify the most probable joint configuration of all classes. In this work, we switch from the ensemble approach to the single model approach. This allows important computational savings. The reduction of inference times is exponential in the difference between the treewidth of the single model and the number of classes. We adopt moreover a more sophisticated approach for the structural learning of the class subgraph. The proposed single models outperforms alternative approaches for mul- tilabel classification such as binary relevance and ensemble of classifier chains.},
year      = {2014},
pages     = {145--159}}

@ARTICLE{antonucci2014e,
author = {Mau\'a, D.D. and de Campos, C.P. and Benavoli, A. and Antonucci, A.},
title     = {Probabilistic inference in credal networks: new complexity results},
journal   = {Journal of Artificial Intelligence Research},
year      = {2014},
volume    = {50},
pages     = {603--637}}


@ARTICLE{antonucci2014d,
title = {Approximate credal network updating by linear programming with applications to decision making},
journal = {International Journal of Approximate Reasoning},
author={Antonucci, A. and de Campos, C.P. and Huber, D. and Zaffalon, M.},
journal={International Journal of Approximate Reasoning},
volume={58},
pages={25--38},
year={2015},
publisher={Elsevier}
}

@INPROCEEDINGS{antonucci2014c,
author = {Mau\'a, D.D. and de Campos, C.P. and Antonucci, A.},
title = {Hidden {M}arkov models with imprecisely specified parameters},
booktitle = {Proceedings of the Brazilian Conference on Intelligent Systems},
abstract = {Hidden Markov models {(HMMs)} are widely used models for sequential data. As with other probabilistic graphical models, they require the specification of precise probability values, which can be too restrictive for some domains, espe- cially when data are scarce or costly to acquire. We present a generalized version of HMMs, whose quantification can be done by sets of, instead of single, probability distributions. Our models have the ability to suspend judgment when there is not enough statistical evidence, and can serve as a sensitivity analysis tool for standard non-stationary HMMs. Efficient inference algorithms are developed to address standard HMM usage such as the computation of likelihoods and most probable explanations. Experiments with real data show that the use of imprecise probabilities leads to more reliable inferences without compromising efficiency.},
year = {2014}}

@ARTICLE{antonucci2014b,
author = {Antonucci, A. and de Rosa, R. and Giusti, A. and Cuzzolin, F.},
title = {Robust classification of multivariate time series by imprecise hidden {M}arkov models},
journal = {International Journal of Approximate Reasoning},
volume = {56},
number = {B},
pages = {249--263},
year = {2015},
abstract = {A novel technique to classify time series with imprecise hidden Markov models is presented. The learning of these models is achieved by coupling the EM algorithm with the imprecise Dirichlet model. In the stationarity limit, each model corresponds to an imprecise mixture of Gaussian densities, this reducing the problem to the classification of static, imprecise-probabilistic, information. Two classifiers, one based on the expected value of the mixture, the other on the Bhattacharyya distance between pairs of mixtures, are developed. The computation of the bounds of these descriptors with respect to the imprecise quantification of the parameters is reduced to, respectively, linear and quadratic optimization tasks, and hence efficiently solved. Classification is performed by extending the k-nearest neighbors approach to interval-valued data. The classifiers are credal, meaning that multiple class labels can be returned in the output. Experiments on benchmark datasets for computer vision show that these methods achieve the required robustness whilst outperforming other precise and imprecise methods.}}

@INPROCEEDINGS{antonucci2014a, 
author = {Antonucci, A. and Karlsson, A. and Sundgren, D.},
editor = {Laurent, A. and Strauss, O. and Bouchon-Meunier, B. and Yager, R.R.},
title = {Decision making with hierarchical credal sets},
booktitle = {Information Processing and Management of Uncertainty in Knowledge-Based Systems},
publisher = {Springer},
series = {Communications in Computer and Information Science},
volume = {444},
year = {2014},
pages = {456--465}}

@INPROCEEDINGS{antonucci2013a,
title = {Approximating credal network inferences by linear programming},
editor = {van der Gaag, L. C.},
publisher = {Springer},
address = {Berlin Heidelberg},
series = {Lecture Notes in Artificial Intelligence},
volume = {7958},
booktitle = {Proceedings of the 12th European Conference on Symbolic and Quantitative Approaches to Reasoning {w}ith Uncertainty},
author = {Antonucci, A. and de Campos, C.P. and Huber, D. and Zaffalon, M.},
pages = {13-25},
year = {2013},
abstract = {An algorithm for approximate credal network updating is presented. The problem in its general formulation is a multilinear optimization task, which can be linearized by an appropriate rule for fixing all the local models apart from those of a single variable. This simple idea can be iterated and quickly leads to very accurate inferences. The approach can also be specialized to classification with credal networks based on the maximality criterion. A complexity analysis for both the problem and the algorithm is reported together with numerical experiments, which confirm the good performance of the method. While the inner approximation produced by the algorithm gives rise to a classifier which might return a subset of the optimal class set, preliminary empirical results suggest that the accuracy of the optimal class set is seldom affected by the approximate probabilities.}}

@INPROCEEDINGS{antonucci2013b,
title = {Temporal data classification by imprecise dynamical models},
editor = {Cozman, F. and Denoeux, T. and Destercke, S. and Seidenfeld, T.},
publisher = {SIPTA},
booktitle = {ISIPTA '13: Proceedings of the Eighth International Symposium on Imprecise Probability: Theories and Applications},
author = {Antonucci, A. and de Rosa, R. and Giusti, A. and Cuzzolin, F.},
year = {2013},
abstract = { We propose a new methodology to classify temporal data with imprecise hidden Markov models. For each sequence we learn a different model by coupling the EM algorithm with the imprecise Dirichlet model. As a model descriptor, we consider the expected value of the observable variable in the limit of stationar- ity of the Markov chain. In the imprecise case, only the bounds of this descriptor can be evaluated. In practice the sequence, which can be regarded as a trajectory in the feature space, is summarized by a hyperbox in the same space. We classify these static but interval-valued data by a credal generalization of the k-nearest neighbors algorithm. Experiments on benchmark datasets for computer vision show that the method achieves the required robustness whilst outperforming other precise and imprecise methods.}}

@INPROCEEDINGS{antonucci2013c,
title = {CREDO: a military decision-support system based on credal networks},
booktitle = {Proceedings of the 16th Conference on Information Fusion ({FUSION} 2013)},
author = {Antonucci, A. and Huber, D. and Zaffalon, M. and Luginb\"uhl, P. and Chapman, I. and Ladouceur, R.},
year = {2013},
abstract = {A software tool especially designed for military domains to create and query decision-support systems is presented. Credal networks, which are Bayesian networks whose parameters have the freedom to vary in convex sets, are used to model the relations among the system variables. A novel elicitation procedure of these sets, which allows the military experts to report their knowledge by purely qualitative judgements, is proposed. Two high-level fusion procedures to cope with multiple experts in this framework are also derived. All these features are supported by the software and demonstrated in an application to space security tested during the last NATO multinational experiment.}}

@INPROCEEDINGS{antonucci2013d,
author = {Antonucci, A. and Corani, G. and Mau\'a, D.D. and Gabaglio, S.},
title = {An {E}nsemble of {B}ayesian {N}etworks for {M}ultilabel {C}lassification},
booktitle = {Proceedings of the 23rd International Joint Conference on Artificial Intelligence ({IJCAI}-13)},
year = {2013},
abstract= {We present a novel approach for multilabel classification based on an ensemble of Bayesian networks. The class variables are connected by a tree; each model of the ensemble uses a different class as root of the tree. We assume the features to be conditionally independent given the classes, thus generalizing the naive Bayes assumption to the multiclass case. This assumption allows us to optimally identify the correlations between classes and features; such correlations are moreover shared across all models of the ensemble. Inferences are drawn from the ensemble via logarithmic opinion pooling. To minimize Hamming loss, we compute the marginal probability of the classes by running standard inference on each Bayesian network in the ensemble, and then pooling the inferences. To instead minimize the subset 0/1 loss, we pool the joint distributions of each model and cast the problem as a MAP inference in the corresponding graphical model. Experiments show that the approach is competitive with state-of-the-art methods for multilabel classification.}}

@INPROCEEDINGS{antonucci2013e,
title = {On the {C}omplexity of {S}trong and {E}pistemic {C}redal {N}etworks},
booktitle = {Proceedings of the 29th Conference on Uncertainty in Artificial Intelligence},
author = {Mau\'a, D.D. and de Campos, C.P. and Benavoli, A. and Antonucci, A.},
pages = {391--400},
year = {2013},
abstract = {Credal networks are graph-based statistical models whose parameters take values in a set, instead of being sharply specified as in traditional statistical models (e.g., Bayesian networks). The computational complexity of inferences on such models depends on the irrelevance/independence concept adopted. In this paper, we study inferential complexity under the concepts of epistemic irrelevance and strong independence. We show that inferences under strong independence are NP-hard even in trees with ternary variables. We prove that under epistemic irrelevance the polynomial time complexity of inferences in credal trees is not likely to extend to more general models (e.g. singly connected networks). These results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard, and settle several open questions regarding computational complexity.}}

@INPROCEEDINGS{antonucci2012a,
author = {Antonucci, A.},
title = {An Interval-Valued Dissimilarity Measure for Belief Functions Based
	on Credal Semantics},
booktitle = {Belief Functions: Theory and Applications - Proceedings of the 2nd
	International Conference on Belief Functions, Compi{\`e}gne, France,
	9-11 May 2012},
  year = {2012},
  editor = {Denoeux, T. and Masson M.H.},
  volume = {164},
  series = {Advances in Soft Computing},
  pages = {37-44},
  publisher = {Springer},
  abstract = {Evidence theory extends Bayesian probability theory by allowing for
	a more expressive model of subjective uncertainty. Besides standard
	interpretation of belief functions, where uncertainty corresponds
	to probability masses which might refer to whole subsets of the possibility
	space, credal semantics can be also considered. Accordingly, a belief
	function can be identified with the whole set of probability mass
	functions consistent with the beliefs induced by the masses. Following
	this interpretation, a novel, set-valued, dissimilarity measure with
	a clear behavioral interpretation can be defined. We describe the
	main features of this new measure and comment the relation with other
	measures proposed in the literature.}
}



@INPROCEEDINGS{antonucci2011c,
  author = {Antonucci, A.},
  title = {The Imprecise Noisy-OR Gate},
  booktitle = {FUSION 2011: Proceedings of the 14th International Conference on
	Information Fusion},
  year = {2011},
  pages = {709-715},
  publisher = {IEEE},
  abstract = {The noisy-OR gate is an important tool for a compact elicitation of
	the conditional probabilities of a Bayesian network. An imprecise-probabilistic
	version of this model, where sets instead of single distributions
	are used to model uncertainty about the inhibition of the causal
	factors, is proposed. This transforms the original Bayesian network
	into a so-called credal network. Despite the higher computational
	complexity generally characterizing inference on credal networks,
	it is possible to prove that, exactly as for Bayesian networks, the
	local complexity to update probabilities on an imprecise noisy-OR
	gate takes only linear, instead of exponential, time in the number
	of causes. This result is also extended to fault tree analysis and
	allows for a fast fusion of the causal effects on models with an
	imprecise-probabilistic quantification of the initiating events.}
}

@PHDTHESIS{antonucci,
  author = {Antonucci, A.},
  title = {Imprecise Probabilistic Graphical Models: Equivalent Representations,
	Inference Algorithms and Applications},
  school = {Universit\`a della Svizzera Italiana},
  year = {2008},
  month = {April},
  abstract = {Credal networks are probabilistic graphical models that extend Bayesian
	nets to deal with imprecision in probability, and can actually be
	regarded as sets of Bayesian nets. Credal nets appear to be powerful
	means to represent and deal with many important and challenging problems
	in uncertain reasoning. The counterpart of having more freedom in
	the modeling phase is an increased inferential complexity of inferences,
	e.g., the so-called belief updating becomes a hard task even on relatively
	simple topologies. In this thesis, I start my investigation on credal
	networks by considering equivalent representations of those models.
	More specifically, I first deliver a new graphical language, which
	is called decision-theoretic being inspired by the formalism of decision
	graphs, for a unified representation of credal networks of any kind.
	I also present another representation, which is called binarization,
	being in fact a reformulation of a credal network solely based on
	binary variables. Remarkably, I prove that if a credal net is first
	reformulated by its decision-theoretic representation and then by
	the corresponding binarization, the resulting representation is completely
	equivalent. An equivalence relation between Bayesian and credal nets,
	when the reason for the missingness of some of the variables in the
	Bayesian nets is unknown, is also provided. The developed equivalent
	representations are applied to inference problems. First, I show
	that, by a decision-theoretic formulation, the algorithms that have
	been already designed for credal networks, which are mostly referred
	to a specific class of models, called separately specified nets,
	can be generalized to credal networks of any kind. Similar formalisms
	are also employed to solve inference and classification problems
	with missing observations. I also present a state-ofthe- art updating
	algorithm which is based on the equivalent binary representation.
	This algorithm, called GL2U, offers an efficient procedure for approximate
	updating of general credal nets. The quality of the overall approximation
	is investigated by promising numerical experiments. As a further
	theoretical investigation, I consider a classification problem for
	Bayesian networks for which a hardness proof together with a fast
	algorithm for a subclass of models is provided. Finally, two real-world
	applications of credal networks are presented. First, I consider
	a military identification problem, consisting in the detection of
	the goal of an intruder entering a no-fly area. The problem, together
	with the necessary fusion of the information gathered by the sensors
	is mapped by our techniques into a credal network updating task.
	The solution is then obtained by the GL2U algorithm. The second application
	is an environmental model for hazard assessment of debris flows by
	credal networks. A credal network evaluates the level of risk, corresponding
	to the observed values of the triggering factors, for this specific
	natural hazard. For some factors, whose observations are more difficult,
	the corresponding soft evidential information is embedded by our
	formalism into the structure of the network. This model is employed
	for extensive numerical analysis on the Swiss territory.},
  owner = {antonucci},
  url = {http://doc.rero.ch/record/10745?ln=en}
}

@INPROCEEDINGS{antonucci2009e,
  author = {Antonucci, A. and Benavoli, A. and Zaffalon, M. and de Cooman, G.
	and Hermans, F.},
  title = {Multiple model tracking by imprecise Markov trees},
  booktitle = {FUSION 2009: Proceedings of the 12th International Conference on
	Information Fusion},
  year = {2009},
  publisher = {IEEE},
  abstract = {We present a new procedure for tracking manoeuvring objects by hidden
	Markov chains. It leads to more reliable modelling of the transitions
	between hidden states compared to similar approaches proposed within
	the Bayesian framework: we adopt convex sets of probability mass
	functions rather than single 'precise probability' specifications,
	in order to provide a more realistic and cautious model of the manoeuvre
	dynamics. In general, the downside of such increased freedom in the
	modelling phase is a higher inferential complexity. However, the
	simple topology of hidden Markov chains allows for efficient tracking
	of the object through a recently developed belief propagation algorithm.
	Furthermore, the imprecise specification of the transitions can produce
	so-called indecision, meaning that more than one model may be suggested
	by our method as a possible explanation of the target kinematics.
	In summary, our approach leads to a multiple-model estimator whose
	performance, investigated through extensive numerical tests, turns
	out to be more accurate and robust than that of Bayesian ones.}
}

@INPROCEEDINGS{antonucci2007b,
  author = {Antonucci, A. and Br\"uhlmann, R. and Piatti, A. and Zaffalon, M.},
  title = {Credal networks for military identification problems},
  booktitle = {{ISIPTA} '07: Proceedings of the fifth International Symposium on on
	Imprecise Probability: Theories and Applications},
  year = {2007},
  editor = {de Cooman, G, Vejnarov\'a, J., Zaffalon, M.},
  pages = {1--10},
  address = {Prague (Czech Republic)},
  publisher = {Action M Agency},
  abstract = {Credal networks are imprecise probabilistic graphical models generalizing
	Bayesian networks to convex sets of probability mass functions. This
	makes credal networks particularly suited to capture and model expert
	knowledge under very general conditions, including states of qualitative
	and incomplete knowledge. In this paper, we present a credal network
	for risk evaluation in case of intrusion of civil aircrafts into
	a no-fly zone. The different factors relevant for this evaluation,
	together with an independence structure over them, are initially
	identified. These factors are observed by sensors, whose reliabilities
	can be affected by variable external factors, and even by the behavior
	of the intruder. A model of these observation mechanisms, and the
	necessary fusion scheme for the information returned by the sensors
	measuring the same factor, are both completely embedded into the
	structure of the credal network. A pool of experts, facilitated in
	their task by specific techniques to convert qualitative judgments
	into imprecise probabilistic assessments, has made possible the quantification
	of the network. We show the capabilities of the proposed network
	by means of some preliminary tests referred to simulated scenarios.
	Overall, we can regard this application as an useful tool to support
	military experts in their decision, but also as a quite general imprecise-probability
	paradigm for information fusion.}
}

@ARTICLE{antonucci2009a,
  author = {Antonucci, A. and Br\"uhlmann, R. and Piatti, A. and Zaffalon, M.},
  title = {Credal networks for military identification problems},
  journal = {International Journal of Approximate Reasoning},
  year = {2009},
  volume = {50},
  pages = {666--679},
  number = {2},
  abstract = {Credal networks are imprecise probabilistic graphical models generalizing
	Bayesian networks to convex sets of probability mass functions. This
	makes credal networks particularly suited to model expert knowledge
	under very general conditions, including states of qualitative and
	incomplete knowledge. In this paper, we present a credal network
	for risk evaluation in case of intrusion of civil aircrafts into
	a restricted flight area. The different factors relevant for this
	evaluation, together with an independence structure over them, are
	initially identified. These factors are observed by sensors, whose
	reliabilities can be affected by variable external factors, and even
	by the behaviour of the intruder. A model of these observation processes,
	and the necessary fusion scheme for the information returned by the
	sensors measuring the same factor, are both completely embedded into
	the structure of the credal network. A pool of experts, facilitated
	in their task by specific techniques to convert qualitative judgements
	into imprecise probabilistic assessments, has made possible the quantification
	of the network. We show the capabilities of the proposed model by
	means of some preliminary tests referred to simulated scenarios.
	Overall, we can regard this application as a useful tool to support
	military experts in their decision, but also as a quite general imprecise-probability
	paradigm for information fusion.}
}

@INPROCEEDINGS{antonucci2011d,
  author = {Antonucci, A. and de Campos, C.P.},
  title = {Decision Making by Credal Nets},
  booktitle = {Proceedings of the International Conference on Intelligent Human-Machine
	Systems and Cybernetics (IHMSC 2011)},
  year = {2011},
  volume = {1},
  pages = {201-204},
  address = {Hangzhou (China)},
  publisher = {IEEE},
  abstract = {Credal nets are probabilistic graphical models which extend Bayesian
	nets to cope with sets of distributions. This feature makes the model
	particularly suited for the implementation of classifiers and knowledge-based
	systems. When working with sets of (instead of single) probability
	distributions, the identification of the optimal option can be based
	on different criteria, some of them eventually leading to multiple
	choices. Yet, most of the inference algorithms for credal nets are
	designed to compute only the bounds of the posterior probabilities.
	This prevents some of the existing criteria from being used. To overcome
	this limitation, we present two simple transformations for credal
	nets which make it possible to compute decisions based on the maximality
	and E-admissibility criteria without any modification in the inference
	algorithms. We also prove that these decision problems have the same
	complexity of standard inference, being NP^PP-hard for general credal
	nets and NP-hard for polytrees.}
}

@INPROCEEDINGS{antonucci2012b,
  author = {Antonucci, A. and Cattaneo, M. and Corani,G.},
  title = {Likelihood-Based Robust Classification with Bayesian Networks},
  booktitle = {Advances in Computational Intelligence},
  year = {2012},
  editor = {Greco, S. and Bouchon-Meunier, B. and Coletti, G. and Fedrizzi, M.
	and Matarazzo, B. and Yager, R.R.},
  volume = {299},
  series = {Communications in Computer and Information Science},
  pages = {491--500},
  publisher = {Springer},
  abstract = {Bayesian networks are commonly used for classification: a structural
	learning algorithm determines the network graph, while standard approaches
	estimate the model parameters from data. Yet, with few data the corresponding
	assessments can be unreliable. To gain robustness in this phase,
	we consider a likelihood-based learning approach, which takes all
	the model quantifications whose likelihood exceeds a given threshold.
	A new classification algorithm based on this approach is presented.
	Notably, this is a credal classifier, i.e., more than a single class
	can be returned in output. This is the case when the Bayesian networks
	consistent with the threshold constraint assign different class labels
	to a test instance. This is the first classifier of this kind for
	general topologies. Experiments show how this approach provide the
	desired robustness.}
}

@INPROCEEDINGS{antonucci2011a,
  author = {Antonucci, A. and Cattaneo, M. and Corani, G.},
  title = {The Naive Hierarchical Credal Classifier},
  booktitle = {ISIPTA '11: Proceedings of the seventh International Symposium on
	Imprecise Probability: Theories and Applications},
  year = {2011},
  pages = {21-30},
  publisher = {SIPTA},
  abstract = {The naive credal classifier extends the classical naive Bayes classifier
	to imprecise probabilities, substituting the uniform prior by the
	imprecise Dirichlet model. As an alternative to the naive credal
	classifier, we present a hierarchical likelihood-based approach,
	which extends in a novel way the naive Bayes towards imprecise probabilities;
	in particular, it considers any possible quantification (each one
	defining a naive Bayes classifier) apart from those assigning to
	the available data a probability below a given threshold level. Besides
	the available supervised data, in the likelihood evaluation we also
	consider the instance to be classified, for which the value of the
	class variable is assumed missing-at-random. We obtain a closed formula
	to compute the dominance according to the maximality criterion for
	any threshold level. As there are currently no well-established metrics
	for comparing credal classifiers which have considerably different
	determinacy, we compare the two classifiers when they have comparable
	determinacy, finding that in those cases they generate almost equivalent
	classifications.}
}

@INPROCEEDINGS{antonucci2012c,
  author = {Antonucci, A. and Corani, G. and Gabaglio, S.},
  title = {Active Learning by the Naive Credal Classifier},
  booktitle = {Proceeding of the sixth European Workshop on Probabilistic Graphical
	Models (PGM 2012)},
  year = {2012},
  editor = {Cano, A. and G\'omez-Olmedo, M. and Nielsen, T.D.},
  pages = {3--10},
  abstract = {In standard classification a training set of supervised instances
	is given. In a more general setup, some supervised instances are
	available, while further ones should be chosen from an unsupervised
	set and then annotated. As the annotation step is costly, active
	learning algorithms are used to select which instances to annotate
	to maximally increase the classification performance while annotating
	only a limited number of them. Several active learning algorithms
	are based on the naive Bayes classifier. We work instead with the
	naive credal classifier, namely an extension of naive Bayes to imprecise
	probability. We propose two novel methods for active learning based
	on the naive credal classifier. Empirical comparisons show performance
	comparable or slightly superior to that of approaches solely based
	on the naive Bayes.}
}

@INPROCEEDINGS{antonucci2010a,
  author = {Antonucci, A. and Cuzzolin, F.},
  title = {Credal Sets Approximation by Lower Probabilities: Application to
	Credal Networks},
  booktitle = {Computational Intelligence for Knowledge-Based Systems Design, 13th
	International Conference on Information Processing and Management
	of Uncertainty, IPMU 2010, Dortmund, Germany, June 28 - July 2, 2010.
	Proceedings},
  year = {2010},
  editor = {H\"ullermeier, E. and Kruse, R. and Hoffmann, F.},
  volume = {6178},
  series = {Lecture Notes in Computer Science},
  pages = {716-725},
  publisher = {Springer},
  abstract = {Credal sets are closed convex sets of probability mass functions.
	The lower probabilities specified by a credal set for each element
	of the power set can be used as constraints defining a second credal
	set. This simple procedure produces an outer approximation, with
	a bounded number of extreme points, for general credal sets. The
	approximation is optimal in the sense that no other lower probabilities
	can specify smaller supersets of the original credal set. Notably,
	in order to be computed, the approximation does not need the extreme
	points of the credal set, but only its lower probabilities. This
	makes the approximation particularly suited for credal networks,
	which are a generalization of Bayesian networks based on credal sets.
	Although most of the algorithms for credal networks updating only
	return lower posterior probabilities, the suggested approximation
	can be used to evaluate (as an outer approximation of) the posterior
	credal set. This makes it possible to adopt more sophisticated decision
	making criteria, without having to replace existing algorithms. The
	quality of the approximation is investigated by numerical tests.}
}

@INPROCEEDINGS{antonucci2009g,
  author = {Antonucci, A. and Piatti, A.},
  title = {Modeling unreliable observations in Bayesian networks by credal networks},
  booktitle = {Scalable Uncertainty Management, Third International Conference,
	SUM 2009, Washington, DC, USA, September 28-30, 2009. Proceedings},
  year = {2009},
  editor = {Godo, L. and Pugliese, A.},
  volume = {5785},
  series = {Lecture Notes in Computer Science},
  pages = {28--39},
  publisher = {Springer},
  abstract = {Bayesian networks are probabilistic graphical models widely employed
	in AI for the implementation of knowledge-based systems. Standard
	inference algorithms can update the beliefs about a variable of interest
	in the network after the observation of some other variables. This
	is usually achieved under the assumption that the observations could
	reveal the actual states of the variables in a fully reliable way.
	We propose a procedure for a more general modeling of the observations,
	which allows for updating beliefs in different situations, including
	various cases of unreliable, incomplete, uncertain and also missing
	observations. This is achieved by augmenting the original Bayesian
	network with a number of auxiliary variables corresponding to the
	observations. For a flexible modeling of the observational process,
	the quantification of the relations between these auxiliary variables
	and those of the original Bayesian network is done by credal sets,
	i.e., convex sets of probability mass functions. Without any lack
	of generality, we show how this can be done by simply estimating
	the bounds for the likelihoods of the observations. Overall, the
	Bayesian network is transformed into a credal network, for which
	a standard updating problem has to be solved. Finally, a number of
	transformations that might simplify the updating of the resulting
	credal network is provided.},
  owner = {antonucci}
}

@INPROCEEDINGS{antonucci2007c,
  author = {Antonucci, A. and Piatti, A. and Zaffalon, M.},
  title = {Credal networks for operational risk measurement and management},
  booktitle = {Proceedings of the 11th International Conference on Knowledge-Based
	and Intelligent Information \& Engineering Systems: KES2007, Lectures
	Notes in Computer Science},
  year = {2007},
  editor = {Apolloni, B. and Howlett, R. J. and Jain, L. C.},
  volume = {4693},
  pages = {604--611},
  publisher = {Springer},
  abstract = {According to widely accepted guidelines for self-regulation, the capital
	requirements of a bank should relate to the level of risk with respect
	to three different categories. Among them, operational risk is the
	more difficult to assess, as it requires merging expert judgments
	and quantitative information about the functional structure of the
	bank. A number of approaches to the evaluation of operational risk
	based on Bayesian networks have been recently considered. In this
	paper, we propose credal networks, which are a generalization of
	Bayesian networks to imprecise probabilities, as a more appropriate
	framework for the measurement and management of operational risk.
	The reason is the higher flexibility provided by credal networks
	compared to Bayesian networks in the quantification of the probabilities
	underlying the model: this makes it possible to represent human expertise
	required for these evaluations in a credible and robust way. We use
	a real-world application to demonstrate these features and to show
	how to measure operational risk by means of algorithms for inference
	over credal nets. This is shown to be possible, also in the case
	when the observation of some factor is vague.}
}

@INPROCEEDINGS{antonucci2011b,
  author = {Antonucci, A. and de Rosa, R. and Giusti, A.},
  title = {Action Recognition by Imprecise Hidden Markov Models},
  booktitle = {Proceedings of the 2011 International Conference on Image Processing,
	Computer Vision and Pattern Recognition, IPCV 2011},
  year = {2011},
  pages = {474-478},
  publisher = {CSREA Press},
  abstract = {Hidden Markov models (HMMs) are powerful tools to capture the dynamics
	of a human action by providing a sufficient level of abstraction
	to recognise what two video sequences, depicting the same kind of
	action, have in common. If the sequence is short and hence only few
	data are available, the EM algorithm, which is generally employed
	to learn HMMs, might return unreliable estimates. As a possible solution
	to this problem, a robust version of the EM algorithm, which provides
	an interval-valued quantification of the HMM probabilities is provided.
	This takes place in an imprecise-probabilistic framework, where action
	recognition can be based on the (bounds of the) likelihood assigned
	by an imprecise HMM to the considered video sequence. Experiments
	show that this approach is quite effective in discriminating the
	hard-to-recognise sequences from the easy ones. In practice, either
	the recognition algorithm returns a set of action labels, which typically
	includes the right one, either a single answer, which is very likely
	to be correct, is provided.}
}

@INPROCEEDINGS{antonucci2004b,
  author = {Antonucci, A. and Salvetti, A. and Zaffalon, M.},
  title = {Assessing debris flow hazard by credal nets},
  booktitle = {Proceedings of the Second International Conference on {S}oft {M}ethods
	in {P}robability and {S}tatistics ({SMPS}-2004) - Soft Methodology
	and Random Information Systems},
  year = {2004},
  editor = {Lopez-Diaz, M. and Gil, M. A. and Grzegorzewski, P. and Hryniewicz,
	O. and Lawry, J.},
  pages = {125--132},
  publisher = {Springer},
  url = {http://www.idsia.ch/~zaffalon/papers/smps2004.pdf}
}

@INPROCEEDINGS{antonucci2004a,
  author = {Antonucci, A. and Salvetti, A. and Zaffalon, M.},
  title = {Hazard assessment of debris flows by credal networks},
  booktitle = {iEMSs 2004: Complexity and Integrated Resources Management, Transactions
	of the 2nd Biennial Meeting of the International Environmental Modelling
	and Software Society},
  year = {2004},
  editor = {Pahl-Wostl, C. and Schmidt, S. and Rizzoli, A. E. and Jakeman, A.
	J.},
  pages = {98--103},
  organization = {Manno, Switzerland},
  publisher = {iEMSs},
  abstract = {Debris flows are destructive natural hazards that affect human life,
	buildings, and infrastructures. Despite their importance, debris
	flows are only partially understood, and human expertise still plays
	a key role for hazard identification. This paper proposes filling
	the modelling gap by using credal networks, an imprecise-probability
	model. The model uses a directed graph to capture the causal relationships
	between the triggering factors of debris flows. Quantitative influences
	are represented by probability intervals, determined from historical
	data, expert knowledge, and theoretical models. Most importantly,
	the model joins the empirical and the quantitative modelling levels,
	in the direction of more credible inferences. The model is evaluated
	on real case studies related to dangerous areas of the Ticino Canton,
	southern Switzerland. The case studies highlight the good capabilities
	of the model: for all the areas the model produces significant probabilities
	of hazard.},
  url = {http://www.iemss.org/iemss2004/pdf/ai/antohaza.pdf}
}

@INBOOK{antonucci2007d,
  pages = {125--132},
  title = {Credal networks for hazard assessment of debris flows},
  publisher = {Kropp, J., Scheffran, J.},
  year = {2007},
  author = {Antonucci, A. and Salvetti, A. and Zaffalon, M.},
  series = {Nova Science},
  address = {New York},
  booktitle = {Progress of Artificial Intelligence in Sustainability Science}
}

@ARTICLE{antonucci2009b,
  author = {Antonucci, A. and Yi, S. and de Campos, C.P. and Zaffalon, M.},
  title = {Generalized loopy 2U: a new algorithm for approximate inference in
	credal networks},
  journal = {International Journal of Approximate Reasoning},
  year = {2010},
  volume = {55},
  pages = {474--484},
  number = {5},
  abstract = {Credal networks generalize Bayesian networks by relaxing the requirement
	of precision of probabilities. Credal networks are considerably more
	expressive than Bayesian networks, but this makes belief updating
	NP-hard even on polytrees. We develop a new efficient algorithm for
	approximate belief updating in credal networks. The algorithm is
	based on an important representation result we prove for general
	credal networks: that any credal network can be equivalently reformulated
	as a credal network with binary variables; moreover, the transformation,
	which is considerably more complex than in the Bayesian case, can
	be implemented in polynomial time. The equivalent binary credal network
	is then updated by L2U, a loopy approximate algorithm for binary
	credal networks. Overall, we generalize L2U to non-binary credal
	networks, obtaining a scalable algorithm for the general case, which
	is approximate only because of its loopy nature. The accuracy of
	the inferences with respect to other state-of-the-art algorithms
	is evaluated by extensive numerical tests.}
}

@INPROCEEDINGS{antonucci2005a,
  author = {Antonucci, A. and Zaffalon, M.},
  title = {Fast algorithms for robust classification with {B}ayesian nets},
  booktitle = {Proceedings of the fourth {I}nternational {S}ymposium on {I}mprecise
	{P}robabilities and {T}heir {A}pplications ({ISIPTA}'06)},
  year = {2005},
  editor = {Cozman, F. G. and Nau, R. and Seidenfeld, T.},
  pages = {11-20},
  address = {Manno (Switzerland)},
  publisher = {SIPTA},
  abstract = {We focus on a well-known classification task with expert systems based
	on Bayesian networks: predicting the state of a target variable given
	an incomplete observation of the other variables in the network,
	i.e., an observation of a subset of all the possible variables. To
	provide conclusions robust to near-ignorance about the process that
	prevents some of the variables from being observed, it has recently
	been derived a new rule, called conservative updating. With this
	paper we address the problem to efficiently compute the conservative
	updating rule for robust classification with Bayesian networks. We
	show first that the general problem is NP-hard, thus establishing
	a fundamental limit to the possibility to do robust classification
	efficiently. Then we define a wide subclass of Bayesian networks
	that does admit efficient computation. We show this by developing
	a new classification algorithm for such a class, which extends substantially
	the limits of efficient computation with respect to the previously
	existing algorithm.}
}

@INPROCEEDINGS{antonucci2006a,
  author = {Antonucci, A. and Zaffalon, M.},
  title = {Equivalence between {B}ayesian and credal nets on an updating problem},
  booktitle = {Proceedings of third international conference on {S}oft {M}ethods
	in {P}robability and {S}tatistics ({SMPS}-2006)},
  year = {2006},
  editor = {Lawry, J. and Miranda, E. and Bugarin, A. and Li, S. and Gil, M.
	A. and Grzegorzewski, P. and Hryniewicz, O.},
  pages = {223--230},
  publisher = {Springer},
  abstract = {We establish an intimate connection between Bayesian and credal nets.
	Bayesian nets are precise graphical models, credal nets extend Bayesian
	nets to imprecise probability. We focus on traditional belief updating
	with credal nets, and on the kind of belief updating that arises
	with Bayesian nets when the reason for the missingness of some of
	the unobserved variables in the net is unknown. We show that the
	two updating problems are formally the same.}
}

@INPROCEEDINGS{antonucci2006c,
  author = {Antonucci, A. and Zaffalon, M.},
  title = {Locally specified credal networks},
  booktitle = {PGM'06: Proceedings of the third European Workshop on Probabilistic
	Graphical Models},
  year = {2006},
  editor = {Studen\'y, M. and Vomlel, J.},
  pages = {25--34},
  address = {Prague (Czech Republic)},
  publisher = {Action M Agency},
  abstract = {Credal networks are models that extend Bayesian nets to deal with
	imprecision in probability, and can actually be regarded as sets
	of Bayesian nets. Evidence suggests that credal nets are a powerful
	means to represent and deal with many important and challenging problems
	in uncertain reasoning. We give examples to show that some of these
	problems can only be modelled by credal nets called non-separately
	specified. These, however, are still missing a graphical representation
	language and solution algorithms. The situation is quite the opposite
	with separately specified credal nets, which have been the subject
	of much study and algorithmic development. This paper gives two major
	contributions. First, it delivers a new graphical language to formulate
	any type of credal network, both separately and non-separately specified.
	Second, it shows that any non-separately specified net represented
	with the new language can be easily transformed into an equivalent
	separately specified net, defined over a larger domain. This result
	opens up a number of new perspectives and concrete outcomes: first
	of all, it immediately enables the existing algorithms for separately
	specified credal nets to be applied to non-separately specified ones.}
}

@ARTICLE{antonucci2008b,
  author = {Antonucci, A. and Zaffalon, M.},
  title = {Decision-Theoretic Specification of Credal Networks: A Unified Language
	for Uncertain Modeling with Sets of Bayesian Networks},
  journal = {International Journal of Approximate Reasoning},
  year = {2008},
  volume = {49},
  pages = {345--361},
  number = {2},
  abstract = {Credal networks are models that extend Bayesian nets to deal with
	imprecision in probability, and can actually be regarded as sets
	of Bayesian nets. Credal nets appear to be powerful means to represent
	and deal with many important and challenging problems in uncertain
	reasoning. We give examples to show that some of these problems can
	only be modeled by credal nets called non-separately specified. These,
	however, are still missing a graphical representation language and
	updating algorithms. The situation is quite the opposite with separately
	specified credal nets, which have been the subject of much study
	and algorithmic development. This paper gives two major contributions.
	First, it delivers a new graphical language to formulate any type
	of credal network, both separately and non-separately specified.
	Second, it shows that any non-separately specified net represented
	with the new language can be easily transformed into an equivalent
	separately specified net, defined over a larger domain. This result
	opens up a number of new outlooks and concrete outcomes: first of
	all, it immediately enables the existing algorithms for separately
	specified credal nets to be applied to non-separately specified ones.
	We explore this possibility for the 2U algorithm: an algorithm for
	exact updating of singly connected credal nets, which is extended
	by our results to a class of non-separately specified models. We
	also consider the problem of inference on Bayesian networks, when
	the reason that prevents some of the variables from being observed
	is unknown. The problem is first reformulated in the new graphical
	language, and then mapped into an equivalent problem on a separately
	specified net. This provides a first algorithmic approach to this
	kind of inference, which is also proved to be NP-hard by similar
	transformations based on our formalism.}
}

@ARTICLE{antonucci2007a,
  author = {Antonucci, A. and Zaffalon, M.},
  title = {Fast algorithms for robust classification with {B}ayesian nets},
  journal = {International Journal of Approximate Reasoning},
  year = {2007},
  volume = {44},
  pages = {200--223},
  number = {3},
  abstract = {We focus on a well-known classification task with expert systems based
	on Bayesian networks: predicting the state of a target variable given
	an incomplete observation of the other variables in the network,
	i.e., an observation of a subset of all the possible variables. To
	provide conclusions robust to near-ignorance about the process that
	prevents some of the variables from being observed, it has recently
	been derived a new rule, called conservative updating. With this
	paper we address the problem to efficiently compute the conservative
	updating rule for robust classification with Bayesian networks. We
	show first that the general problem is NP-hard, thus establishing
	a fundamental limit to the possibility to do robust classification
	efficiently. Then we define a wide subclass of Bayesian networks
	that does admit efficient computation. We show this by developing
	a new classification algorithm for such a class, which extends substantially
	the limits of efficient computation with respect to the previously
	existing algorithm. The algorithm is formulated as a variable elimination
	procedure, whose computation time is linear in the input size.}
}

@INPROCEEDINGS{antonucci2006b,
  author = {Antonucci, A. and Zaffalon, M. and Ide, J.S. and Cozman, F.G.},
  title = {Binarization Algorithms for Approximate Updating in Credal Nets},
  booktitle = {STAIRS'06: Proceedings of the third European Starting AI Researcher
	Symposium},
  year = {2006},
  editor = {Penserini, L. and Peppas, P. and Perini, A.},
  pages = {120--131},
  address = {Amsterdam (Netherlands)},
  publisher = {IOS Press},
  abstract = {Credal networks generalize Bayesian networks relaxing numerical parameters.
	This considerably expands expressivity, but makes belief updating
	a hard task even on polytrees. Nevertheless, if all the variables
	are binary, polytree-shaped credal networks can be efficiently updated
	by the 2U algorithm. In this paper we present a binarization algorithm,
	that makes it possible to approximate an updating problem in a credal
	net by a corresponding problem in a credal net over binary variables.
	The procedure leads to outer bounds for the original problem. The
	binarized nets are in general multiply connected, but can be updated
	by the loopy variant of 2U. The quality of the overall approximation
	is investigated by promising numerical experiments.}
}

@INPROCEEDINGS{antonucci2008a,
  author = {Antonucci, A. and Zaffalon, M. and Yi, S. and de Campos, C.P.},
  title = {Generalized loopy 2U: a new algorithm for approximate inference in
	credal networks},
  booktitle = {PGM'08: Proceedings of the Fourth European Workshop on Probabilistic
	Graphical Models},
  year = {2008},
  editor = {Jaeger, M. and Nielsen, T. D.},
  pages = {17--24},
  address = {Hirtshals (Denmark)},
  abstract = {Credal nets generalize Bayesian nets by relaxing the requirement of
	precision of probabilities. Credal nets are considerably more expressive
	than Bayesian nets, but this makes belief updating NP-hard even on
	polytrees. We develop a new efficient algorithm for approximate belief
	updating in credal nets. The algorithm is based on an important representation
	result we prove for general credal nets: that any credal net can
	be equivalently reformulated as a credal net with binary variables;
	moreover, the transformation, which is considerably more complex
	than in the Bayesian case, can be implemented in polynomial time.
	The equivalent binary credal net is updated by L2U, a loopy approximate
	algorithm for binary credal nets. Thus, we generalize L2U to non-binary
	credal nets, obtaining an accurate and scalable algorithm for the
	general case, which is approximate only because of its loopy nature.
	The accuracy of the inferences is evaluated by empirical tests.}
}

@INPROCEEDINGS{antonucci2009d,
  author = {Benavoli, A. and Antonucci, A.},
  title = {Aggregating Imprecise Probabilistic Knowledge},
  booktitle = {ISIPTA '09: Proceedings of the Sixth International Symposium on Imprecise
	Probability: Theories and Applications},
  year = {2009},
  editor = {Augustin, T., Coolen, F., Moral, S., Troffaes, M.C.M.},
  pages = {31--40},
  publisher = {SIPTA},
  note = {accepted for publication},
  abstract = {The problem of aggregating two or more sources of information containing
	knowledge about a same domain is considered. We propose an aggregation
	rule for the case where the available information is modeled by coherent
	lower previsions, corresponding to convex sets of probability mass
	functions. The consistency between aggregated beliefs and sources
	of information is discussed. A closed formula, which specializes
	our rule to a particular class of models, is also derived. Finally,
	an alternative explanation of Zadeh's paradox is provided.}
}

@ARTICLE{antonucci2010c,
  author = {Benavoli, A. and Antonucci, A.},
  title = {Aggregating Imprecise Probabilistic Knowledge: application to Zadeh's
	paradox and sensor networks},
  journal = {International Journal of Approximate Reasoning},
  year = {2010},
  volume = {51},
  pages = {1014--1028},
  number = {9},
  abstract = {The problem of aggregating two or more sources of information containing
	knowl- edge about a common domain is considered. We propose an aggregation
	frame- work for the case where the available information is modelled
	by coherent lower previsions, corresponding to convex sets of probability
	mass functions. The con- sistency between aggregated beliefs and
	sources of information is discussed. A closed formula, which specializes
	our rule to a particular class of models, is also derived. Two applications
	consisting in a possible explanation of Zadeh‚Äôs paradox and an
	algorithm for estimation fusion in sensor networks are finally reported.}
}

@INPROCEEDINGS{antonucci2009c,
  author = {de Cooman, G. and Hermans, F. and Antonucci, A. and Zaffalon, M.},
  title = {Epistemic irrelevance in credal networks: the case of imprecise Markov
	trees},
  booktitle = {ISIPTA '09: Proceedings of the Sixth International Symposium on Imprecise
	Probability: Theories and Applications},
  year = {2009},
  editor = {Augustin, T., Coolen, F., Moral, S., Troffaes, M.C.M.},
  pages = {149--158},
  publisher = {SIPTA},
  abstract = {We replace strong independence in credal networks with the weaker
	notion of epistemic irrelevance. Focusing on directed trees, we show
	how to combine local credal sets into a global model, and we use
	this to construct and justify an exact message-passing algorithm
	that computes updated beliefs for a variable in the tree. The algorithm,
	which is essentially linear in the number of nodes, is formulated
	entirely in terms of coherent lower previsions. We supply examples
	of the algorithm's operation, and report an application to on-line
	character recognition that illustrates the advantages of our model
	for prediction.}
}

@ARTICLE{antonucci2010b,
  author = {de Cooman, G. and Hermans, F. and Antonucci, A. and Zaffalon, M.},
  title = {Epistemic irrelevance in credal nets: the case of imprecise {M}arkov
	trees},
  journal = {International Journal of Approximate Reasoning},
  year = {2010},
  volume = {51},
  pages = {1029--1052},
  number = {9},
  abstract = {We focus on credal nets, which are graphical models that generalise
	Bayesian nets to imprecise probability. We replace the notion of
	strong independence commonly used in credal nets with the weaker
	notion of epistemic irrelevance, which is arguably more suited for
	a behavioural theory of probability. Focusing on directed trees,
	we show how to combine the given local uncertainty models in the
	nodes of the graph into a global model, and we use this to construct
	and justify an exact message-passing algorithm that computes updated
	beliefs for a variable in the tree. The algorithm, which is linear
	in the number of nodes, is formulated entirely in terms of coherent
	lower previsions, and is shown to satisfy a number of rationality
	requirements. We supply examples of the algorithm‚Äôs operation,
	and report an application to on-line character recognition that illustrates
	the advantages of our approach for prediction. We comment on the
	perspectives, opened by the availability, for the first time, of
	a truly efficient algorithm based on epistemic irrelevance.}
}

@INPROCEEDINGS{antonucci2012d,
author = {Corani, G. and Antonucci, A. and de Rosa, R.},
title = {Compression-based AODE classifiers},
booktitle = {Proceedings 20th European Conference on Artificial Intelligence (ECAI 2012)},
year = {2012},
pages = {264--269},
abstract = {We propose the COMP-AODE classifier, which adopts the compression-based
	approach to average the posterior probabilities computed by different
	non-naive classifier (SPODEs). COMP-AODE improves classification performance
	over the well-known AODE model. COMP-AODE assumes a uniform prior
	over the SPODEs; we then develop the credal classifier COMP-AODE*,
	substituting the uniform prior by a set of priors. COMP-AODE* returns
	more classes when the classification is prior-dependent, namely if
	the most probable class varies with the prior adopted over the SPODEs.
	COMP-AODE* achieves higher classification utility than both COMP-AODE
	and AODE.},
editor    = {De Raedt, L. and Bessiere, C. and Dubois, D. and Doherty, P. and Frasconi, P. and Heintz, F. and Lucas, P.J.F.},
publisher = {IOS Press},
series    = {Frontiers in Artificial Intelligence and Applications},
volume    = {242},
year      = {2012}
}

@INBOOK{antonucci2009f,
  chapter = {2},
  title = {Building knowledge-based expert systems: a tutorial},
  publisher = {Nova Science Publishers},
  year = {2010},
  editor = {Baswell, A.R.},
  author = {Piatti, A. and Antonucci, A. and Zaffalon, M.},
  volume = {11},
  address = {New York},
  abstract = {Knowledge-based systems are computer programs achieving expert-level
	competence in solving problems for specific task areas. This chapter
	is a tutorial on the construction of knowledge-based systems in the
	theoretical framework of credal networks. Credal networks are a generalization
	of Bayesian networks where credal sets, i.e., closed convex sets
	of probability measures, are used instead of precise probabilities.
	This allows for a more flexible process of elicitation than in the
	case of Bayesian networks. In fact, credal sets allow to represent
	ambiguity, contrast and contradiction in a natural and realistic
	way. The procedure we propose is based on a sharp distinction between
	the domain knowledge and the process linking this knowledge to the
	perceived evidence, which we call the observational process. This
	distinction leads to a very flexible representation of both domain
	knowledge and knowledge about the way the information is collected,
	together with a procedure of aggregation of the information coming
	from the different sources. The overall procedure is illustrated
	along the chapter by a simple knowledge-based system for the prediction
	of the result of a football match.},
  booktitle = {Advances in Mathematics Research}
}

@INPROCEEDINGS{antonucci2008c,
  author = {Salvetti, A. and Antonucci, A. and Zaffalon, M.},
  title = {Spatially distributed identification of debris flow source areas
	by credal networks},
  booktitle = {iEMSs 2008: International Congress on Environmental Modelling and
	Software Integrating Sciences and Information Technology for Environmental
	Assessment and Decision Making (Transactions of the 4th Biennial
	Meeting of the International Environmental Modelling and Software
	Society)},
  year = {2008},
  editor = {S√†nchez-Marr√®, M. and B√©jar, J. and Comas, J. and Rizzoli, A.
	E. and Guariso, G.},
  pages = {380--387},
  address = {Manno, Switzerland},
  publisher = {iEMSs},
  abstract = {Debris flows represent a very destructive natural hazard, affecting
	buildings, transport infrastructures, and, very often, causing human
	losses in mountain regions. That makes the identification of potential
	source areas of debris flows inside a watershed particularly important.
	In this paper we present a general identification procedure based
	on the credal network (that is an imprecise probabilistic graphical
	model generalizing Bayesian networks) originally introduced by Antonucci
	et al. (2004). That model is significantly improved by a more refined
	description of the meteorological and hydrological processes contributing
	to the debris flow initiation. As a counterpart of such improvement,
	the model pays a slight increase in terms of computational time for
	identifications. That does not prevent its extensive, spatially distributed,
	application to whole basins, thanks to a preliminary deterministic
	analysis that rejects local areas where the triggering of a debris
	flow cannot take place. The overall procedure is tested for a debris
	flow prone watershed in Southern Switzerland. The model detects the
	areas in the basin more prone to debris flow initiation and also
	shows that different rainfall return periods produce different patterns
	of hazard in the basin. That makes it possible with this procedure
	to determine the return period of the critical rainfall that triggers
	debris flow as a result of channel-bed failure in a specific point
	along the drainage network.}
}

